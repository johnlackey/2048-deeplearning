<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>2048</title>

  <link href="style/main.css" rel="stylesheet" type="text/css">
  <link rel="shortcut icon" href="favicon.ico">
  <link rel="apple-touch-icon" href="meta/apple-touch-icon.png">
  <link rel="apple-touch-startup-image" href="meta/apple-touch-startup-image-640x1096.png" media="(device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2)"> <!-- iPhone 5+ -->
  <link rel="apple-touch-startup-image" href="meta/apple-touch-startup-image-640x920.png"  media="(device-width: 320px) and (device-height: 480px) and (-webkit-device-pixel-ratio: 2)"> <!-- iPhone, retina -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, target-densitydpi=160dpi, initial-scale=1.0, maximum-scale=1, user-scalable=no, minimal-ui">
</head>
 <body onload="start();">
  <div class="container">
    <div class="heading">
      <h1 class="title">2048</h1>
      <div class="scores-container">
        <div class="score-container">0</div>
        <div class="best-container">0</div>
        <br />
        <div class="value-container">""</div>
        <div class="key-container">""</div>
      </div>
    </div>

    <div class="above-game">
      <p class="game-intro">Join the numbers and get to the <strong>2048 tile!</strong></p>
      <a class="restart-button">New Game</a>
    </div>

    <div class="game-container">
      <div class="game-message">
        <p></p>
        <div class="lower">
	        <a class="keep-playing-button">Keep going</a>
          <a class="retry-button">Try again</a>
        </div>
      </div>

      <div class="grid-container">
        <div class="grid-row">
          <div class="grid-cell"></div>
          <div class="grid-cell"></div>
          <div class="grid-cell"></div>
          <div class="grid-cell"></div>
        </div>
        <div class="grid-row">
          <div class="grid-cell"></div>
          <div class="grid-cell"></div>
          <div class="grid-cell"></div>
          <div class="grid-cell"></div>
        </div>
        <div class="grid-row">
          <div class="grid-cell"></div>
          <div class="grid-cell"></div>
          <div class="grid-cell"></div>
          <div class="grid-cell"></div>
        </div>
        <div class="grid-row">
          <div class="grid-cell"></div>
          <div class="grid-cell"></div>
          <div class="grid-cell"></div>
          <div class="grid-cell"></div>
        </div>
      </div>

      <div class="tile-container">

      </div>
    </div>
  </div>

   <div>
       <table border="1" style="text-align:right">
           <tr>
               <th></th>
               <th id="col0">1</th>
               <th id="col1">2/4/8/16</th>
               <th id="col2">4/16/64/256</th>
               <th id="col3">8/64/512/4096</th>
               <th id="col4">16/256/4096</th>
               <th id="col5">32/1024</th>
               <th id="col6">64/4096</th>
               <th id="col7">128</th>
               <th id="col8">256</th>
               <th id="col9">512</th>
               <th id="col10">1024</th>
               <th id="col11">2048</th>
               <th id="col12">4096</th>
               <th id="col13">8192</th>
               <th id="col14">16384</th>
               <th id="col15">32768</th>
           </tr>
           <tr>
               <td>experience replay size:</td>
               <td id="brain_0_0"></td>
               <td id="brain_0_1"></td>
               <td id="brain_0_2"></td>
               <td id="brain_0_3"></td>
               <td id="brain_0_4"></td>
               <td id="brain_0_5"></td>
               <td id="brain_0_6"></td>
               <td id="brain_0_7"></td>
               <td id="brain_0_8"></td>
               <td id="brain_0_9"></td>
               <td id="brain_0_10"></td>
               <td id="brain_0_11"></td>
               <td id="brain_0_12"></td>
               <td id="brain_0_13"></td>
               <td id="brain_0_14"></td>
               <td id="brain_0_15"></td>
           </tr>
           <tr>
               <td>exploration epsilon:</td>
               <td id="brain_1_0"></td>
               <td id="brain_1_1"></td>
               <td id="brain_1_2"></td>
               <td id="brain_1_3"></td>
               <td id="brain_1_4"></td>
               <td id="brain_1_5"></td>
               <td id="brain_1_6"></td>
               <td id="brain_1_7"></td>
               <td id="brain_1_8"></td>
               <td id="brain_1_9"></td>
               <td id="brain_1_10"></td>
               <td id="brain_1_11"></td>
               <td id="brain_1_12"></td>
               <td id="brain_1_13"></td>
               <td id="brain_1_14"></td>
               <td id="brain_1_15"></td>
           </tr>
           <tr>
               <td>age:</td>
               <td id="brain_2_0"></td>
               <td id="brain_2_1"></td>
               <td id="brain_2_2"></td>
               <td id="brain_2_3"></td>
               <td id="brain_2_4"></td>
               <td id="brain_2_5"></td>
               <td id="brain_2_6"></td>
               <td id="brain_2_7"></td>
               <td id="brain_2_8"></td>
               <td id="brain_2_9"></td>
               <td id="brain_2_10"></td>
               <td id="brain_2_11"></td>
               <td id="brain_2_12"></td>
               <td id="brain_2_13"></td>
               <td id="brain_2_14"></td>
               <td id="brain_2_15"></td>
           </tr>
           <tr>
               <td>average Q-learning loss:</td>
               <td id="brain_3_0"></td>
               <td id="brain_3_1"></td>
               <td id="brain_3_2"></td>
               <td id="brain_3_3"></td>
               <td id="brain_3_4"></td>
               <td id="brain_3_5"></td>
               <td id="brain_3_6"></td>
               <td id="brain_3_7"></td>
               <td id="brain_3_8"></td>
               <td id="brain_3_9"></td>
               <td id="brain_3_10"></td>
               <td id="brain_3_11"></td>
               <td id="brain_3_12"></td>
               <td id="brain_3_13"></td>
               <td id="brain_3_14"></td>
               <td id="brain_3_15"></td>
           </tr>
           <tr>
               <td>smooth-ish reward:</td>
               <td id="brain_4_0"></td>
               <td id="brain_4_1"></td>
               <td id="brain_4_2"></td>
               <td id="brain_4_3"></td>
               <td id="brain_4_4"></td>
               <td id="brain_4_5"></td>
               <td id="brain_4_6"></td>
               <td id="brain_4_7"></td>
               <td id="brain_4_8"></td>
               <td id="brain_4_9"></td>
               <td id="brain_4_10"></td>
               <td id="brain_4_11"></td>
               <td id="brain_4_12"></td>
               <td id="brain_4_13"></td>
               <td id="brain_4_14"></td>
               <td id="brain_4_15"></td>
           </tr>
       </table>
   </div>
    <p class="game-explanation">
      <strong class="important">How to play:</strong> Use your <strong>arrow keys</strong> to move the tiles. When two tiles with the same number touch, they <strong>merge into one!</strong>
    </p>
    <hr>
    <p>
    <strong class="important">Note:</strong> This site is the official version of 2048. You can play it on your phone via <a href="http://git.io/2048">http://git.io/2048.</a> All other apps or sites are derivatives or fakes, and should be used with caution.
    </p>
    <hr>
    <p>
    Created by <a href="http://gabrielecirulli.com" target="_blank">Gabriele Cirulli.</a> Based on <a href="https://itunes.apple.com/us/app/1024!/id823499224" target="_blank">1024 by Veewo Studio</a> and conceptually similar to <a href="http://asherv.com/threes/" target="_blank">Threes by Asher Vollmer.</a>
    </p>
  <div>
   <h1>State Visualizations</h1>
   
   <div><b>Left</b>: Current input state (quite a useless thing to look at). <b>Right</b>: Average reward over time (this should go up as agent becomes better on average at collecting rewards)</div>
   <canvas id="vis_canvas" width="1000" height="150"></canvas>
   <canvas id="graph_canvas" width="350" height="150"></canvas><br>
   <canvas id="net_canvas" width="2000" height="200"></canvas><br>
   
   <!--<canvas id="canvas" width="700" height="200"></canvas>-->
   <div id="brain_info_div">
       <div>
           <div>
               experience replay size: 4203<br>
               exploration epsilon: 0.9938883248730964<br>
               age: 4205<br>
               average Q-learning loss: 0.1062660890110729<br>
               smooth-ish reward: 0.7147144345566855<br>
           </div>
       </div>
   </div>
   
   <h1>Controls</h1>
   <button onclick="goveryfast()">Go very fast</button>
   <button onclick="gofast()">Go fast</button>
   <button onclick="gonormal()">Go normal speed</button>
   <button onclick="goslow()">Go slow</button><br>
   <button onclick="startlearn()">Start Learning</button>
   <button onclick="stoplearn()">Stop Learning</button>
   
   <textarea id="qspec" style="width:100%; height:200px;">
var side_size = 4;
var highest_value = 2048;
var num_inputs = side_size * side_size * 16; // 9 eyes, each sees 3 numbers (wall, green, red thing proximity)
var num_actions = 4; // 5 possible angles agent can turn
var temporal_window = 0; // amount of temporal memory. 0 = agent lives in-the-moment :)
//var future_reward = 10;
var network_size = num_inputs*temporal_window + num_actions*temporal_window + num_inputs;

// the value function network computes a value of taking any of the possible actions
// given an input state. Here we specify one explicitly the hard way
// but user could also equivalently instead use opt.hidden_layer_sizes = [20,20]
// to just insert simple relu hidden layers.
var layer_defs = [];
layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:network_size});
layer_defs.push({type:'fc', num_neurons: 50, activation:'relu'});
layer_defs.push({type:'fc', num_neurons: 50, activation:'relu'});
layer_defs.push({type:'fc', num_neurons: 50, activation:'relu'});
layer_defs.push({type:'fc', num_neurons: 50, activation:'relu'});
layer_defs.push({type:'regression', num_neurons:num_actions});

// options for the Temporal Difference learner that trains the above net
// by backpropping the temporal difference learning rule.
var tdtrainer_options = {learning_rate:0.001, momentum:0.0, batch_size:64, l2_decay:0.01};

var opt = {};
opt.temporal_window = temporal_window;
opt.experience_size = 30000;
opt.start_learn_threshold = 1000;
opt.gamma = 0.999;
opt.learning_steps_total = 200000;
opt.learning_steps_burnin = 3000;
opt.epsilon_min = 0.005;
opt.epsilon_test_time = 0.0005;
opt.layer_defs = layer_defs;
opt.tdtrainer_options = tdtrainer_options;

var brain = Array(16);
for (i=0;i<16;i++) {
    brain[i] = new deepqlearn.Brain(num_inputs, num_actions, opt); // woohoo
}
   </textarea>
  </div>
  <script src="js/bind_polyfill.js"></script>
  <script src="js/classlist_polyfill.js"></script>
  <script src="js/animframe_polyfill.js"></script>
  <script src="js/keyboard_input_manager.js"></script>
  <script src="js/html_actuator.js"></script>
  <script src="js/grid.js"></script>
  <script src="js/tile.js"></script>
  <script src="js/local_storage_manager.js"></script>
  <script src="js/game_manager.js"></script>
  <script>
    var keyboardInputManager = new KeyboardInputManager;
  </script>
  <script src="js/application.js"></script>
  <script src="js/world.js"></script>
  <script src="js/agent.js"></script>
  <script src="js/convnet.js"></script>
  <script src="js/deepqlearn.js"></script>
  <script src="js/util.js"></script> 
  <script src="js/vis.js"></script>
  <script>
    function draw_net() {
      if(simspeed <=1) {
        // we will always draw at these speeds
      } else {
        if(w.clock % 10 !== 0) return;  // do this sparingly 50
      }
      
      var canvas = document.getElementById("net_canvas");
      var ctx = canvas.getContext("2d");
      var W = canvas.width;
      var H = canvas.height;
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      var L = w.agents[0].brain[w.agents[0].maxPower].value_net.layers;
      var dx = (W - 50)/L.length;
      var x = 10;
      var y = 40;
      ctx.font="12px Verdana";
      ctx.fillStyle = "rgb(0,0,0)";
      ctx.fillText("Value Function Approximating Neural Network:", 10, 14);
      for(var k=0;k<L.length;k++) {
        if(typeof(L[k].out_act)==='undefined') continue; // maybe not yet ready
        var kw = L[k].out_act.w;
        var n = kw.length;
        var dy = (H-50)/n;
        ctx.fillStyle = "rgb(0,0,0)";
        ctx.fillText(L[k].layer_type + "(" + n + ")", x, 35);
        for(var q=0;q<n;q++) {
          var v = Math.floor(kw[q]*1000);
          if(v >= 0) ctx.fillStyle = "rgb(0,0," + v + ")";
          if(v < 0) ctx.fillStyle = "rgb(" + (-v) + ",0,0)";
          ctx.fillRect(x,y,10,10);
          y += 12;
          if(y>H-25) { y = 40; x += 12};
        }
        x += 50;
        y = 40;
      }
    }
    
    var reward_graph = new cnnvis.Graph();
    
    function draw_stats() {
      var canvas = document.getElementById("vis_canvas");
      var ctx = canvas.getContext("2d");
      var W = canvas.width;
      var H = canvas.height;
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      var a = w.agents[0];
      var b = a.brain[w.agents[0].maxPower];
      var netin = b.last_input_array;
      ctx.strokeStyle = "rgb(0,0,0)";
      //ctx.font="12px Verdana";
      //ctx.fillText("Current state:",10,10);
      ctx.lineWidth = 10;
      ctx.beginPath();
      for(var k=0,n=netin.length;k<n;k++) {
        ctx.moveTo(10+k*12, 120);
        ctx.lineTo(10+k*12, 120 - netin[k] * 500);
      }
      ctx.stroke();
      
      if(w.clock % 200 === 0) {
        reward_graph.add(w.clock, b.average_reward_window.get_average());
        var gcanvas = document.getElementById("graph_canvas");
        reward_graph.drawSelf(gcanvas);
      }
    }
    
    // Tick the world
    function tick() {
      if (gameManager.isGameTerminated()) {
          gameTerminated = gameTerminated + 1;
          if (gameTerminated > 2) {
            keyboardInputManager.emit('restart');
          }
      } else {
          gameTerminated = 0;
      }
      w.tick();
      if(!skipdraw || w.clock % 1 === 0) {
        //draw();
        draw_stats();
        draw_net();
        w.agents[0].brain[w.agents[0].maxPower].visSelf(document.getElementById('brain_info_div'));
        var brainValues = w.agents[0].brain[w.agents[0].maxPower].visSelfValues();
        for (var k=0,n=brainValues.length;k<n;k++) {
            var elemId = "brain_" + k + "_" + w.agents[0].maxPower;
            var elem =document.getElementById(elemId);
            elem.innerText = brainValues[k];
        }
        if (isNaN(brainValues[3])) {
            w.agents[0].brain[w.agents[0].maxPower].reset();
        }
      }
    }
    
    var simspeed = 2;
    function goveryfast() {
      window.clearInterval(current_interval_id);
      current_interval_id = setInterval(tick, 0);
      skipdraw = true;
      simspeed = 3;
    }
    function gofast() {
      window.clearInterval(current_interval_id);
      current_interval_id = setInterval(tick, 0);
      skipdraw = false;
      simspeed = 2;
    }
    function gonormal() {
      window.clearInterval(current_interval_id);
      current_interval_id = setInterval(tick, 30);
      skipdraw = false;
      simspeed = 1;
    }
    function goslow() {
      window.clearInterval(current_interval_id);
      current_interval_id = setInterval(tick, 2000);
      skipdraw = false;
      simspeed = 0;
    }
    
    function savenet() {
      var j = w.agents[0].brain.value_net.toJSON();
      var t = JSON.stringify(j);
      document.getElementById('tt').value = t;
    }
    
    function loadnet() {
      var t = document.getElementById('tt').value;
      var j = JSON.parse(t);
      w.agents[0].brain.value_net.fromJSON(j);
      stoplearn(); // also stop learning
      gonormal();
    }
    
    function startlearn() {
      w.agents[0].brain[0].learning = true;
    }
    function stoplearn() {
      w.agents[0].brain[0].learning = false;
    }
    
    function reload() {
      w.agents = [new Agent()]; // this should simply work. I think... ;\
      reward_graph = new cnnvis.Graph(); // reinit
    }
    
    function start() {
      //canvas = document.getElementById("canvas");
      //ctx = canvas.getContext("2d");
      
      w = new World();
      w.agents = [new Agent()];
        keyboardInputManager.emit('restart');
      
      //gofast();
      goslow();
      //tick();
    }
    var current_interval_id;
  </script>
</body>
</html>
